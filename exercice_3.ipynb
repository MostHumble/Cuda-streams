{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGzZcl1b+DOenAKQGnW4MK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-j14Pkm7BD",
        "outputId": "ae8df92c-9b31-496a-fa28-531c06af846b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.11/dist-packages (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqyQ_fyos9t",
        "outputId": "fc92e6ab-bf1e-4777-9730-119249717029"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmptgmpqsa3\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda -c \"--gpu-architecture sm_75 -O2 --default-stream per-thread\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// same kernel with different name\n",
        "__global__ void Kernel_00(float*x, int len)\n",
        "{\n",
        "\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif(tid < len) {\n",
        "\t\tfloat sum = x[tid];\n",
        "\t\tint iter = 0;\n",
        "\n",
        "\t\twhile(iter++ < len) {\n",
        "\t\t\tsum += 1;\n",
        "\t\t}\n",
        "\t\tx[tid] = sum;\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void Kernel_01(float*x, int len)\n",
        "{\n",
        "\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif(tid < len) {\n",
        "\t\tfloat sum = x[tid];\n",
        "\t\tint iter = 0;\n",
        "\n",
        "\t\twhile(iter++ < len) {\n",
        "\t\t\tsum += 1;\n",
        "\t\t}\n",
        "\t\tx[tid] = sum;\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tconst int streamsNum = 2;\n",
        "\tint N=1<<10; // 1Kibi\n",
        "\n",
        "\tint threads_per_block = 128;\n",
        "\tint num_blocks = (threads_per_block + N - 1) / threads_per_block;\n",
        "\n",
        "\tstd::cout << \"Running \" << N << \" (floats) as the input data size.\" << std::endl;\n",
        "\tstd::cout << \"Launching \" << streamsNum << \" cuda streams.\" << std::endl;\n",
        "\n",
        "\t// device property\n",
        "\n",
        "\tcudaDeviceProp device_prop;\n",
        "\tint devID = 0; // use 1st device as default\n",
        "\tcudaGetDeviceProperties(&device_prop, devID);\n",
        "\n",
        "\t// query for priority range\n",
        "\tint priority_l;\n",
        "\tint priority_h;\n",
        "\n",
        "\tcudaDeviceGetStreamPriorityRange(&priority_l, &priority_h);\n",
        "\tprintf(\"Stream priority range: LOW: %d to HIGH: %d on %s\\n\", priority_l, priority_h, device_prop.name);\n",
        "\n",
        "  // paged memory\n",
        "\tfloat *h_a, *h_b;\n",
        "\tcudaMallocHost((void**)&h_a, sizeof(float) * N);\n",
        "\tcudaMallocHost((void**)&h_b, sizeof(float) * N);\n",
        "\n",
        "\tmemset(h_a, 0, sizeof(float) * N);\n",
        "\tmemset(h_b, 0, sizeof(float) * N);\n",
        "\n",
        "\t// device\n",
        "\tfloat *d_a, *d_b;\n",
        "\tcudaMalloc((void**)&d_a, sizeof(float) * N);\n",
        "\tcudaMalloc((void**)&d_b, sizeof(float) * N);\n",
        "\n",
        "\t// streams\n",
        "\tcudaStream_t streams[streamsNum];\n",
        "\tcudaEvent_t  events[streamsNum]; // events for streams\n",
        "\n",
        "\tfor(int i=0; i<streamsNum; i++) {\n",
        "\t\tcudaStreamCreate(&streams[i]);\n",
        "\t\tcudaEventCreate(&events[i]);\n",
        "\t}\n",
        "\n",
        "\t// configure priority for streams\n",
        "\tcudaStreamCreateWithPriority(&streams[0], cudaStreamNonBlocking, priority_l); // stream 0 with low priority\n",
        "\tcudaStreamCreateWithPriority(&streams[1], cudaStreamNonBlocking, priority_h); // stream 1 with high priority\n",
        "\n",
        "\t//cudaStreamCreateWithPriority(&streams[0], cudaStreamNonBlocking, priority_h); // stream 0 with low priority\n",
        "\t//cudaStreamCreateWithPriority(&streams[1], cudaStreamNonBlocking, priority_l); // stream 1 with high priority\n",
        "\n",
        "\t// h2d\n",
        "\tcudaMemcpyAsync(d_a, h_a, sizeof(float)*N, cudaMemcpyHostToDevice, streams[0]);\n",
        "\tcudaMemcpyAsync(d_b, h_b, sizeof(float)*N, cudaMemcpyHostToDevice, streams[1]);\n",
        "\n",
        "\t// low priority kernel\n",
        "\tKernel_00 <<< num_blocks, threads_per_block, 0, streams[0] >>> (d_a, N); // a + x\n",
        "\tcudaEventRecord(events[0], streams[0]);\n",
        "\n",
        "\t// high priority kernel\n",
        "\tKernel_01 <<< num_blocks, threads_per_block, 0, streams[1] >>> (d_b, N); // b + x\n",
        "\tcudaEventRecord(events[1], streams[1]);\n",
        "\n",
        "\tcudaEventSynchronize(events[0]);\n",
        "\tcudaEventSynchronize(events[1]);\n",
        "\n",
        "\t// d2h\n",
        "\tcudaMemcpyAsync(h_a, d_a, sizeof(float)*N, cudaMemcpyDeviceToHost, streams[0]);\n",
        "\tcudaMemcpyAsync(h_b, d_b, sizeof(float)*N, cudaMemcpyDeviceToHost, streams[1]);\n",
        "\n",
        "\tcudaDeviceSynchronize(); // NOTE: this is needed to make sure prev dev opt is done!\n",
        "\n",
        "\t// check results\n",
        "\tint error_a = 0;\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\tif(h_a[i] != N) {\n",
        "\t\t\tprintf(\"h_a[%d] = %f\\n\",i, h_a[i]);\n",
        "\t\t\terror_a += 1;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif(error_a == 0) {\n",
        "\t\tprintf(\"Pass test on h_a!\\n\");\n",
        "\t}\n",
        "\n",
        "\tint error_b = 0;\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\tif(h_b[i] != N) {\n",
        "\t\t\tprintf(\"h_b[%d] = %f\\n\",i, h_b[i]);\n",
        "\t\t\terror_b += 1;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif(error_b == 0) {\n",
        "\t\tprintf(\"Pass test on h_b!\\n\");\n",
        "\t}\n",
        "\t// free\n",
        "\tfor(int i=0; i<streamsNum; i++) {\n",
        "\t\tcudaStreamDestroy(streams[i]);\n",
        "\t\tcudaEventDestroy(events[i]);\n",
        "\t}\n",
        "\n",
        "\tcudaFree(d_a);\n",
        "\tcudaFree(d_b);\n",
        "\n",
        "\tcudaFreeHost(h_a);\n",
        "\tcudaFreeHost(h_b);\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJB99vXUmHMG",
        "outputId": "5a1c7870-e46d-4507-e8a6-1b49ac15c85e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 1024 (floats) as the input data size.\n",
            "Launching 2 cuda streams.\n",
            "Stream priority range: LOW: 0 to HIGH: -5 on Tesla T4\n",
            "Pass test on h_a!\n",
            "Pass test on h_b!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda -c \"--gpu-architecture sm_75 -O2 --default-stream per-thread\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// same kernel with different name\n",
        "__global__ void Kernel_00(float*x, int len)\n",
        "{\n",
        "\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif(tid < len) {\n",
        "\t\tfloat sum = x[tid];\n",
        "\t\tint iter = 0;\n",
        "\n",
        "\t\twhile(iter++ < len) {\n",
        "\t\t\tsum += 1;\n",
        "\t\t}\n",
        "\t\tx[tid] = sum;\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void Kernel_01(float*x, int len)\n",
        "{\n",
        "\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "\tif(tid < len) {\n",
        "\t\tfloat sum = x[tid];\n",
        "\t\tint iter = 0;\n",
        "\n",
        "\t\twhile(iter++ < len) {\n",
        "\t\t\tsum += 1;\n",
        "\t\t}\n",
        "\t\tx[tid] = sum;\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tconst int streamsNum = 2;\n",
        "\tint N=1<<10; // 1Kibi\n",
        "\n",
        "\tint threads_per_block = 128;\n",
        "\tint num_blocks = (threads_per_block + N - 1) / threads_per_block;\n",
        "\n",
        "\tstd::cout << \"Running \" << N << \" (floats) as the input data size.\" << std::endl;\n",
        "\tstd::cout << \"Launching \" << streamsNum << \" cuda streams.\" << std::endl;\n",
        "\n",
        "\t// device property\n",
        "\n",
        "\tcudaDeviceProp device_prop;\n",
        "\tint devID = 0; // use 1st device as default\n",
        "\tcudaGetDeviceProperties(&device_prop, devID);\n",
        "\n",
        "\t// query for priority range\n",
        "\tint priority_l;\n",
        "\tint priority_h;\n",
        "\n",
        "\tcudaDeviceGetStreamPriorityRange(&priority_l, &priority_h);\n",
        "\tprintf(\"Stream priority range: LOW: %d to HIGH: %d on %s\\n\", priority_l, priority_h, device_prop.name);\n",
        "\n",
        "  // paged memory\n",
        "\tfloat *h_a, *h_b;\n",
        "\tcudaMallocHost((void**)&h_a, sizeof(float) * N);\n",
        "\tcudaMallocHost((void**)&h_b, sizeof(float) * N);\n",
        "\n",
        "\tmemset(h_a, 0, sizeof(float) * N);\n",
        "\tmemset(h_b, 0, sizeof(float) * N);\n",
        "\n",
        "\t// device\n",
        "\tfloat *d_a, *d_b;\n",
        "\tcudaMalloc((void**)&d_a, sizeof(float) * N);\n",
        "\tcudaMalloc((void**)&d_b, sizeof(float) * N);\n",
        "\n",
        "\t// streams\n",
        "\tcudaStream_t streams[streamsNum];\n",
        "\tcudaEvent_t  events[streamsNum]; // events for streams\n",
        "\n",
        "\tfor(int i=0; i<streamsNum; i++) {\n",
        "\t\tcudaStreamCreate(&streams[i]);\n",
        "\t\tcudaEventCreate(&events[i]);\n",
        "\t}\n",
        "\n",
        "\t// configure priority for streams\n",
        "\t//cudaStreamCreateWithPriority(&streams[0], cudaStreamNonBlocking, priority_l); // stream 0 with low priority\n",
        "\t//cudaStreamCreateWithPriority(&streams[1], cudaStreamNonBlocking, priority_h); // stream 1 with high priority\n",
        "\n",
        "\tcudaStreamCreateWithPriority(&streams[0], cudaStreamNonBlocking, priority_h); // stream 0 with low priority\n",
        "\tcudaStreamCreateWithPriority(&streams[1], cudaStreamNonBlocking, priority_l); // stream 1 with high priority\n",
        "\n",
        "\t// h2d\n",
        "\tcudaMemcpyAsync(d_a, h_a, sizeof(float)*N, cudaMemcpyHostToDevice, streams[0]);\n",
        "\tcudaMemcpyAsync(d_b, h_b, sizeof(float)*N, cudaMemcpyHostToDevice, streams[1]);\n",
        "\n",
        "\t// low priority kernel\n",
        "\tKernel_00 <<< num_blocks, threads_per_block, 0, streams[0] >>> (d_a, N); // a + x\n",
        "\tcudaEventRecord(events[0], streams[0]);\n",
        "\n",
        "\t// high priority kernel\n",
        "\tKernel_01 <<< num_blocks, threads_per_block, 0, streams[1] >>> (d_b, N); // b + x\n",
        "\tcudaEventRecord(events[1], streams[1]);\n",
        "\n",
        "\tcudaEventSynchronize(events[0]);\n",
        "\tcudaEventSynchronize(events[1]);\n",
        "\n",
        "\t// d2h\n",
        "\tcudaMemcpyAsync(h_a, d_a, sizeof(float)*N, cudaMemcpyDeviceToHost, streams[0]);\n",
        "\tcudaMemcpyAsync(h_b, d_b, sizeof(float)*N, cudaMemcpyDeviceToHost, streams[1]);\n",
        "\n",
        "\tcudaDeviceSynchronize(); // NOTE: this is needed to make sure prev dev opt is done!\n",
        "\n",
        "\t// check results\n",
        "\tint error_a = 0;\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\tif(h_a[i] != N) {\n",
        "\t\t\tprintf(\"h_a[%d] = %f\\n\",i, h_a[i]);\n",
        "\t\t\terror_a += 1;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif(error_a == 0) {\n",
        "\t\tprintf(\"Pass test on h_a!\\n\");\n",
        "\t}\n",
        "\n",
        "\tint error_b = 0;\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\tif(h_b[i] != N) {\n",
        "\t\t\tprintf(\"h_b[%d] = %f\\n\",i, h_b[i]);\n",
        "\t\t\terror_b += 1;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif(error_b == 0) {\n",
        "\t\tprintf(\"Pass test on h_b!\\n\");\n",
        "\t}\n",
        "\t// free\n",
        "\tfor(int i=0; i<streamsNum; i++) {\n",
        "\t\tcudaStreamDestroy(streams[i]);\n",
        "\t\tcudaEventDestroy(events[i]);\n",
        "\t}\n",
        "\n",
        "\tcudaFree(d_a);\n",
        "\tcudaFree(d_b);\n",
        "\n",
        "\tcudaFreeHost(h_a);\n",
        "\tcudaFreeHost(h_b);\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "id": "A-i10hjX85mG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6ce648-6820-4e4d-96fc-fa200d914c8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 1024 (floats) as the input data size.\n",
            "Launching 2 cuda streams.\n",
            "Stream priority range: LOW: 0 to HIGH: -5 on Tesla T4\n",
            "Pass test on h_a!\n",
            "Pass test on h_b!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0T2sQC-yDkI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}