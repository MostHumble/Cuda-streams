{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-j14Pkm7BD",
        "outputId": "01af8fe4-6d20-455d-e09c-5bcafdb5cc4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqyQ_fyos9t",
        "outputId": "d6551346-7ad0-4e47-e41d-949f15fb0d7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpxw_910cv\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile stream_sync.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void testKernel(float*x, int len)\n",
        "{\n",
        "\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\tif(tid < len) {\n",
        "\t\tfloat sum = x[tid];\n",
        "\t\tint iter = 0;\n",
        "\t\twhile(iter++ < len) {\n",
        "\t\t\tsum += 1;\n",
        "\t\t}\n",
        "\t\tx[tid] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\tconst int streamsNum = 2;\n",
        "\tint N=1<<10; // 1K\n",
        "\n",
        "\tif (argc == 2) {\n",
        "\t\tN = atoi(argv[1]);\n",
        "\t}\n",
        "\n",
        "\tif (argc > 2) {\n",
        "\t\tfprintf(stderr, \"Too many arguments! ./stream_sync N .\\n\");\n",
        "\t\texit(1);\n",
        "\t}\n",
        "\n",
        "\tstd::cout << \"Running \" << N << \" (floats) as the input data size.\" << std::endl;\n",
        "\tstd::cout << \"Launching \" << streamsNum << \" cuda streams.\" << std::endl;\n",
        "\n",
        "\tfloat *h_a, *h_b;\n",
        "\n",
        "\tcudaMallocHost((void**)&h_a, sizeof(float) * N);\n",
        "\tcudaMallocHost((void**)&h_b, sizeof(float) * N);\n",
        "\n",
        "\t// init\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\th_a[i] = 0;\n",
        "\t\th_b[i] = 0;\n",
        "\t}\n",
        "\n",
        "\t// device\n",
        "\tfloat *d_a, *d_b;\n",
        "\n",
        "\tcudaMalloc((void**)&d_a, sizeof(float) * N);\n",
        "\tcudaMalloc((void**)&d_b, sizeof(float) * N);\n",
        "\n",
        "\t// streams\n",
        "\tcudaStream_t streams[streamsNum];\n",
        "\tfor(int i=0; i<streamsNum; i++) {\n",
        "\t\tcudaStreamCreate(&streams[i]);\n",
        "\t}\n",
        "\n",
        "\t// h2d\n",
        "\tcudaMemcpyAsync(d_a, h_a, sizeof(float)*N, cudaMemcpyHostToDevice, streams[0]);\n",
        "\tcudaMemcpyAsync(d_b, h_b, sizeof(float)*N, cudaMemcpyHostToDevice, streams[1]);\n",
        "\n",
        "\t// kernel\n",
        "\tint thread_per_block = 128;\n",
        "  int blocks_per_grid = (N + thread_per_block - 1) / thread_per_block;\n",
        "\n",
        "\ttestKernel <<< blocks_per_grid, thread_per_block, 0, streams[0] >>> (d_a, N);\n",
        "\ttestKernel <<< blocks_per_grid, thread_per_block, 0, streams[1] >>> (d_b, N);\n",
        "\n",
        "\t// d2h\n",
        "\tcudaMemcpyAsync(h_a, d_a, sizeof(float)*N, cudaMemcpyDeviceToHost, streams[0]);\n",
        "\tcudaMemcpyAsync(h_b, d_b, sizeof(float)*N, cudaMemcpyDeviceToHost, streams[1]);\n",
        "\n",
        "\tcudaDeviceSynchronize(); // Ensure previous operations are done\n",
        "\n",
        "\tint error_a = 0;\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\tif(h_a[i] != N) {\n",
        "\t\t\tprintf(\"h_a[%d] = %f\\n\",i, h_a[i]);\n",
        "\t\t\terror_a += 1;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif(error_a == 0) {\n",
        "\t\tprintf(\"Pass test on h_a!\\n\");\n",
        "    printf(\"h_a[%d] = %f\\n\",0, h_a[0]);\n",
        "\n",
        "\t}\n",
        "\n",
        "\tint error_b = 0;\n",
        "\tfor(int i=0; i<N; i++) {\n",
        "\t\tif(h_b[i] != N) {\n",
        "\t\t\tprintf(\"h_b[%d] = %f\\n\",i, h_b[i]);\n",
        "\t\t\terror_b += 1;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif(error_b == 0) {\n",
        "\t\tprintf(\"Pass test on h_b!\\n\");\n",
        "    printf(\"h_b[%d] = %f\\n\",0, h_b[0]);\n",
        "\n",
        "\t}\n",
        "\n",
        "\t// free\n",
        "\tfor(int i=0; i<streamsNum; i++) {\n",
        "\t\tcudaStreamDestroy(streams[i]);\n",
        "\t}\n",
        "\n",
        "\tcudaFree(d_a);\n",
        "\tcudaFree(d_b);\n",
        "\n",
        "\tcudaFreeHost(h_a);\n",
        "\tcudaFreeHost(h_b);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJB99vXUmHMG",
        "outputId": "231935b3-78f4-475a-ae22-881e47455653"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stream_sync.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O2 --default-stream per-thread -arch=sm_75 stream_sync.cu -o stream_sync"
      ],
      "metadata": {
        "id": "MbKJ7ptTmIH4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./stream_sync 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aTfM_OPmMOM",
        "outputId": "b5d7342b-8f27-4e04-8eb6-1daf5c790c8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 16 (floats) as the input data size.\n",
            "Launching 2 cuda streams.\n",
            "Pass test on h_a!\n",
            "h_a[0] = 16.000000\n",
            "Pass test on h_b!\n",
            "h_b[0] = 16.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbBxcLfDw-yk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}