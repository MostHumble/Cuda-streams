{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-j14Pkm7BD",
        "outputId": "581fa09e-4d60-4304-a039-e01a9cb417b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqyQ_fyos9t",
        "outputId": "db366652-307f-43b0-df65-0cd0103f9b4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpman70f5t\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADST8G0Na4qU",
        "outputId": "058eba02-9feb-496b-8da3-ec4b01eb4dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl; exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << time << \" ms\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    std::cout.flush();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "\n",
        "int main() {\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    std::cout << \"Hello from CUDA\" << std::endl;\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);\n",
        "    std::cout << \"Time taken: \" << duration.count() << \" microseconds\" << std::endl;\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EQW7LaIn4ly",
        "outputId": "7714a990-3f1f-4370-9fa9-ea063b4327cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from CUDA\n",
            "Time taken: 25 microseconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl; exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << time << \" ms\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    std::cout.flush();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zttn0C-qM93",
        "outputId": "2e813fed-9732-448b-840f-5728b61f193c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h> // For printf\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { printf(\"CUDA error: %s\\n\", cudaGetErrorString(err)); exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    printf(\"Array size: %d elements\\n\", size);\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    printf(\"Launching kernel with %d blocks, %d threads\\n\", numBlocks, blockSize);\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    printf(\"Time: %f ms\\n\", time);\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    printf(\"Program finished\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbkrNNgiqRAv",
        "outputId": "1ca86cb4-a13e-4a81-a181-13cec107baf8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cerr << \"CUDA error: \" << cudaGetErrorString(err) << std::endl; std::cerr.flush(); exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << time << \" ms\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    std::cerr << \"Reached end of main\" << std::endl;\n",
        "    std::cerr.flush();\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urlE9LpTqW_N",
        "outputId": "ca2334a8-d841-45af-9f41-b075299cb2fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iomanip> // For std::setprecision\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl; exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << std::fixed << std::setprecision(9) << time << \" ms\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    std::cout.flush();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KwdxR2xqcJJ",
        "outputId": "466f44e9-0bb0-4a03-c510-f65840af8e41"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl; exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    // checkCuda(cudaDeviceSynchronize()); // Removed this line\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << time << \" ms\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    std::cout.flush();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax57ET2KqeH2",
        "outputId": "259bd374-ac64-48ad-f24a-4cdca35ee5eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda -t\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cout << \"CUDA error: \" << cudaGetErrorString(err) << std::endl; exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx; // Example operation\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i; // Initialize data\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float time;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "\n",
        "    checkCuda(cudaEventRecord(start, 0));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaDeviceSynchronize());\n",
        "    checkCuda(cudaEventRecord(stop, 0));\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << time << \" ms\" << std::endl;\n",
        "    std::cout.flush();\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    std::cout.flush();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0FxYCPjqiaq",
        "outputId": "cde0317c-c478-4f42-cddb-66b1b6b43b3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define checkCuda(err) { if (err != cudaSuccess) { std::cout << \"CUDA error: \" << cudaGetErrorString(err) << \" in \" << __FILE__ << \" at line \" << __LINE__ << std::endl; exit(1); } }\n",
        "\n",
        "__global__ void yourKernel(float *data, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) data[idx] = idx;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 10485760;\n",
        "    std::cout << \"Array size: \" << size << \" elements\" << std::endl;\n",
        "\n",
        "    float *hostData, *deviceData;\n",
        "    checkCuda(cudaMallocHost(&hostData, size * sizeof(float)));\n",
        "    checkCuda(cudaMalloc(&deviceData, size * sizeof(float)));\n",
        "\n",
        "    for (int i = 0; i < size; i++) hostData[i] = i;\n",
        "    checkCuda(cudaMemcpy(deviceData, hostData, size * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    checkCuda(cudaEventCreate(&start));\n",
        "    checkCuda(cudaEventCreate(&stop));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (size + blockSize - 1) / blockSize;\n",
        "    std::cout << \"Launching kernel with \" << numBlocks << \" blocks, \" << blockSize << \" threads\" << std::endl;\n",
        "\n",
        "    // Correct event recording sequence\n",
        "    checkCuda(cudaEventRecord(start));\n",
        "    yourKernel<<<numBlocks, blockSize>>>(deviceData, size);\n",
        "    checkCuda(cudaGetLastError());\n",
        "    checkCuda(cudaEventRecord(stop));  // Record stop event right after kernel launch\n",
        "    checkCuda(cudaEventSynchronize(stop));\n",
        "\n",
        "    float time;\n",
        "    checkCuda(cudaEventElapsedTime(&time, start, stop));\n",
        "\n",
        "    std::cout << \"Time: \" << time << \" ms\" << std::endl;\n",
        "\n",
        "    checkCuda(cudaFreeHost(hostData));\n",
        "    checkCuda(cudaFree(deviceData));\n",
        "    checkCuda(cudaEventDestroy(start));\n",
        "    checkCuda(cudaEventDestroy(stop));\n",
        "\n",
        "    std::cout << \"Program finished\" << std::endl;\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNbwFQvpqqlv",
        "outputId": "b5cc6318-8133-49f3-a92e-8ff1cbc03afe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 10485760 elements\n",
            "Launching kernel with 40960 blocks, 256 threads\n",
            "CUDA error: no error in /tmp/tmpman70f5t/30747c17-d5fb-4412-8595-74b0fe22cf48/single_file.cu at line 33\n",
            "\n"
          ]
        }
      ]
    }
  ]
}