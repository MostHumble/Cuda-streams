{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nvcc4jupyter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T19:30:16.031763Z","iopub.execute_input":"2025-04-01T19:30:16.032061Z","iopub.status.idle":"2025-04-01T19:30:22.678827Z","shell.execute_reply.started":"2025-04-01T19:30:16.032028Z","shell.execute_reply":"2025-04-01T19:30:22.677736Z"}},"outputs":[{"name":"stdout","text":"Collecting nvcc4jupyter\n  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\nDownloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\nInstalling collected packages: nvcc4jupyter\nSuccessfully installed nvcc4jupyter-1.2.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%load_ext nvcc4jupyter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T19:30:24.346676Z","iopub.execute_input":"2025-04-01T19:30:24.346955Z","iopub.status.idle":"2025-04-01T19:31:50.256544Z","shell.execute_reply.started":"2025-04-01T19:30:24.346932Z","shell.execute_reply":"2025-04-01T19:31:50.255682Z"}},"outputs":[{"name":"stdout","text":"Detected platform \"Kaggle\". Running its setup...\nUpdating the package lists...\nInstalling nvidia-cuda-toolkit, this may take a few minutes...\nSource files will be saved in \"/tmp/tmpmaswe_ma\".\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"reference code: ","metadata":{}},{"cell_type":"code","source":"%%cuda -c \"--gpu-architecture sm_75 -O2 --default-stream per-thread\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <cuda_runtime.h>\n\n#define NUM_STREAMS 4  // streams per GPU\n\ntypedef struct {\n\tint len;\n\tfloat *h_input, *h_output;\n\tfloat *d_input, *d_output;\n\tcudaStream_t streams[NUM_STREAMS];  // Multiple streams per GPU\n} MGPUdata;\n\n__global__ void testKernel(float *x, float *y, int len) {\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid < len) {\n\t\ty[tid] = x[tid] + len;  // O(1) instead of O(N)\n\t}\n}\n\nint main(int argc, char **argv) {\n\tint GpuNum = 0;\n\tif (cudaGetDeviceCount(&GpuNum) != cudaSuccess || GpuNum == 0) {\n\t\tprintf(\"No CUDA devices found!\\n\");\n\t\treturn 1;\n\t}\n\tprintf(\"CUDA devices = %i\\n\", GpuNum);\n\n\tconst int N = 100000;\n\tMGPUdata mgpu[GpuNum];\n\n\tint threads_per_block = 128;\n\tint num_blocks = (N + threads_per_block - 1) / threads_per_block;\n\n\tfor (int i = 0; i < GpuNum; i++) {\n\t\tcudaSetDevice(i);\n\n\t\t// Allocate memory\n\t\tcudaMalloc((void**)&mgpu[i].d_input, sizeof(float) * N);\n\t\tcudaMalloc((void**)&mgpu[i].d_output, sizeof(float) * N);\n\t\tcudaMallocHost((void**)&mgpu[i].h_input, sizeof(float) * N);\n\t\tcudaMallocHost((void**)&mgpu[i].h_output, sizeof(float) * N);\n\n\t\tcudaMemset(mgpu[i].h_input, 0, sizeof(float) * N);\n\n\t\t// Create multiple streams\n\t\tfor (int s = 0; s < NUM_STREAMS; s++) {\n\t\t\tcudaStreamCreate(&mgpu[i].streams[s]);\n\t\t}\n\t}\n\n\tint chunk_size = N / NUM_STREAMS;\n\n\tfor (int i = 0; i < GpuNum; i++) {\n\t\tcudaSetDevice(i);\n\n\t\tfor (int s = 0; s < NUM_STREAMS; s++) {\n\t\t\tint offset = s * chunk_size;\n\n\t\t\tcudaMemcpyAsync(mgpu[i].d_input + offset, mgpu[i].h_input + offset,\n\t\t\t                chunk_size * sizeof(float), cudaMemcpyHostToDevice, mgpu[i].streams[s]);\n\n\t\t\tint stream_blocks = (chunk_size + threads_per_block - 1) / threads_per_block;\n\t\t\ttestKernel<<<stream_blocks, threads_per_block, 0, mgpu[i].streams[s]>>>(\n\t\t\t\tmgpu[i].d_input + offset, mgpu[i].d_output + offset, chunk_size);\n\n\t\t\tcudaMemcpyAsync(mgpu[i].h_output + offset, mgpu[i].d_output + offset,\n\t\t\t                chunk_size * sizeof(float), cudaMemcpyDeviceToHost, mgpu[i].streams[s]);\n\t\t}\n\t}\n\n\t// Synchronize and cleanup\n\tfor (int i = 0; i < GpuNum; i++) {\n\t\tcudaSetDevice(i);\n\n\t\t// Sync all streams\n\t\tfor (int s = 0; s < NUM_STREAMS; s++) {\n\t\t\tcudaStreamSynchronize(mgpu[i].streams[s]);\n\t\t\tcudaStreamDestroy(mgpu[i].streams[s]);\n\t\t}\n\n\t\tif (mgpu[i].h_input) cudaFreeHost(mgpu[i].h_input);\n\t\tif (mgpu[i].h_output) cudaFreeHost(mgpu[i].h_output);\n\t\tif (mgpu[i].d_input) cudaFree(mgpu[i].d_input);\n\t\tif (mgpu[i].d_output) cudaFree(mgpu[i].d_output);\n\t}\n\n\treturn 0;\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%cuda -c \"--gpu-architecture sm_75 -O2 --default-stream per-thread\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <cuda_runtime.h>\n\n#define NUM_STREAMS 4  // streams per GPU\n\ntypedef struct {\n\tint len;\n\tfloat *h_input, *h_output;\n\tfloat *d_input, *d_output;\n\tcudaStream_t streams[NUM_STREAMS];  // Multiple streams per GPU\n} MGPUdata;\n\n__global__ void testKernel(float *x, float *y, int len) {\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid < len) {\n\t\ty[tid] = x[tid] + len;  // O(1) instead of O(N)\n\t}\n}\n\nint main(int argc, char **argv) {\n\tint GpuNum = 0;\n\tif (cudaGetDeviceCount(&GpuNum) != cudaSuccess || GpuNum == 0) {\n\t\tprintf(\"No CUDA devices found!\\n\");\n\t\treturn 1;\n\t}\n\tprintf(\"CUDA devices = %i\\n\", GpuNum);\n\n\tconst int N = 100000;\n\tMGPUdata mgpu[GpuNum];\n\n\tint threads_per_block = 128;\n\tint num_blocks = (N + threads_per_block - 1) / threads_per_block;\n\n\tfor (int i = 0; i < GpuNum; i++) {\n\t\tcudaSetDevice(i);\n\n\t\t// Allocate memory\n\t\tcudaMalloc((void**)&mgpu[i].d_input, sizeof(float) * N);\n\t\tcudaMalloc((void**)&mgpu[i].d_output, sizeof(float) * N);\n\t\tcudaMallocHost((void**)&mgpu[i].h_input, sizeof(float) * N);\n\t\tcudaMallocHost((void**)&mgpu[i].h_output, sizeof(float) * N);\n\n\t\tcudaMemset(mgpu[i].h_input, 0, sizeof(float) * N);\n\n\t\t// Create multiple streams\n\t\tfor (int s = 0; s < NUM_STREAMS; s++) {\n\t\t\tcudaStreamCreate(&mgpu[i].streams[s]);\n\t\t}\n\t}\n\n\tint chunk_size = N / NUM_STREAMS;\n\n\tfor (int i = 0; i < GpuNum; i++) {\n\t\tcudaSetDevice(i);\n\n\t\tfor (int s = 0; s < NUM_STREAMS; s++) {\n\t\t\tint offset = s * chunk_size;\n\n\t\t\tcudaMemcpyAsync(mgpu[i].d_input + offset, mgpu[i].h_input + offset,\n\t\t\t                chunk_size * sizeof(float), cudaMemcpyHostToDevice, mgpu[i].streams[s]);\n\n\t\t\tint stream_blocks = (chunk_size + threads_per_block - 1) / threads_per_block;\n\t\t\ttestKernel<<<stream_blocks, threads_per_block, 0, mgpu[i].streams[s]>>>(\n\t\t\t\tmgpu[i].d_input + offset, mgpu[i].d_output + offset, chunk_size);\n\n\t\t\tcudaMemcpyAsync(mgpu[i].h_output + offset, mgpu[i].d_output + offset,\n\t\t\t                chunk_size * sizeof(float), cudaMemcpyDeviceToHost, mgpu[i].streams[s]);\n\t\t}\n\t}\n\n\t// Synchronize and cleanup\n\tfor (int i = 0; i < GpuNum; i++) {\n\t\tcudaSetDevice(i);\n\n\t\t// Sync all streams\n\t\tfor (int s = 0; s < NUM_STREAMS; s++) {\n\t\t\tcudaStreamSynchronize(mgpu[i].streams[s]);\n\t\t\tcudaStreamDestroy(mgpu[i].streams[s]);\n\t\t}\n\n\t\tif (mgpu[i].h_input) cudaFreeHost(mgpu[i].h_input);\n\t\tif (mgpu[i].h_output) cudaFreeHost(mgpu[i].h_output);\n\t\tif (mgpu[i].d_input) cudaFree(mgpu[i].d_input);\n\t\tif (mgpu[i].d_output) cudaFree(mgpu[i].d_output);\n\t}\n\n\treturn 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T20:10:14.731446Z","iopub.execute_input":"2025-04-01T20:10:14.731757Z","iopub.status.idle":"2025-04-01T20:10:16.225216Z","shell.execute_reply.started":"2025-04-01T20:10:14.731730Z","shell.execute_reply":"2025-04-01T20:10:16.224541Z"}},"outputs":[{"name":"stdout","text":"CUDA devices = 2\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}